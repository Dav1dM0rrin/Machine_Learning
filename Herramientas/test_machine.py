"""
Sistema de Machine Learning para Predicci√≥n de Transporte P√∫blico
Proyecto: Miner√≠a de Datos 2025-2
Algoritmos: Random Forest Regressor y XGBoost Classifier
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.ensemble import RandomForestRegressor
from xgboost import XGBClassifier
from sklearn.metrics import (mean_squared_error, r2_score, mean_absolute_error,
                            accuracy_score, classification_report, confusion_matrix,
                            precision_score, recall_score, f1_score)
from sklearn.preprocessing import LabelEncoder
import joblib
import warnings
warnings.filterwarnings('ignore')

# Configuraci√≥n de visualizaci√≥n
plt.style.use('seaborn-v0_8-darkgrid')
sns.set_palette("husl")

# ============================================
# CARGAR Y PREPARAR DATOS
# ============================================
def cargar_y_preparar_datos(ruta_csv='transporte_limpio.csv'):
    """
    Carga y realiza Feature Engineering avanzado
    """
    print("\n" + "="*70)
    print("üìÇ CARGANDO Y PREPARANDO DATOS")
    print("="*70)
    
    df = pd.read_csv(ruta_csv)
    print(f"‚úÖ Registros cargados: {len(df)}")
    print(f"‚úÖ Columnas: {list(df.columns)}")
    
    # Convertir fecha
    df['Fecha'] = pd.to_datetime(df['Fecha'], format='%d/%m/%Y')
    
    # Feature Engineering: Extraer caracter√≠sticas temporales
    df['Mes'] = df['Fecha'].dt.month
    df['A√±o'] = df['Fecha'].dt.year
    df['DiaMes'] = df['Fecha'].dt.day
    df['Trimestre'] = df['Fecha'].dt.quarter
    
    # Caracter√≠sticas categ√≥ricas mejoradas
    df['EsFinDeSemana'] = df['DiaSemana'].isin([6, 7]).astype(int)
    df['EsLaboralPico'] = df['DiaSemana'].isin([1, 2, 3, 4, 5]).astype(int)
    
    # Temporada (basado en an√°lisis del dataset)
    def obtener_temporada(mes):
        if mes in [3, 4, 5, 9, 10, 11]:  # Meses de pandemia y restricciones
            return 'Restriccion'
        elif mes in [6, 7, 8]:  # Meses de reapertura
            return 'Reapertura'
        else:
            return 'Normal'
    
    df['Temporada'] = df['Mes'].apply(obtener_temporada)
    
    # Calcular variaci√≥n respecto a d√≠a t√≠pico
    df['VariacionLaboral'] = (df['Pasajeros/dia'] / df['Pasajeros dia tipico laboral']) - 1
    df['VariacionSabado'] = (df['Pasajeros/dia'] / df['Pasajeros dia sabado']) - 1
    
    # Llenar NaN con 0
    df['VariacionLaboral'].fillna(0, inplace=True)
    df['VariacionSabado'].fillna(0, inplace=True)
    
    print(f"\n‚ú® Features creados:")
    print(f"   ‚Ä¢ Temporales: Mes, A√±o, DiaMes, Trimestre")
    print(f"   ‚Ä¢ Categ√≥ricos: EsFinDeSemana, EsLaboralPico, Temporada")
    print(f"   ‚Ä¢ Variaciones: VariacionLaboral, VariacionSabado")
    
    return df

# ============================================
# ALGORITMO 1: RANDOM FOREST REGRESSOR (OPTIMIZADO)
# ============================================
def entrenar_random_forest(df):
    """
    Random Forest optimizado para predecir pasajeros diarios
    """
    print("\n" + "="*70)
    print("üå≥ ALGORITMO 1: RANDOM FOREST REGRESSOR")
    print("="*70)
    
    # Preparar datos
    df_rf = df.copy()
    df_rf = df_rf.dropna(subset=['Pasajeros/dia'])
    
    # Encoders para variables categ√≥ricas
    le_ciudad = LabelEncoder()
    le_sistema = LabelEncoder()
    le_temporada = LabelEncoder()
    
    df_rf['Ciudad_encoded'] = le_ciudad.fit_transform(df_rf['Ciudad'])
    df_rf['Sistema_encoded'] = le_sistema.fit_transform(df_rf['Sistema'])
    df_rf['Temporada_encoded'] = le_temporada.fit_transform(df_rf['Temporada'])
    
    # Caracter√≠sticas mejoradas
    features = [
        'Ciudad_encoded', 'Sistema_encoded', 'DiaSemana',
        'Pasajeros dia tipico laboral', 'Pasajeros dia sabado', 
        'Pasajeros dia festivo', 'Mes', 'A√±o', 'DiaMes', 'Trimestre',
        'EsFinDeSemana', 'EsLaboralPico', 'Temporada_encoded',
        'VariacionLaboral', 'VariacionSabado'
    ]
    
    X = df_rf[features]
    y = df_rf['Pasajeros/dia']
    
    # Divisi√≥n estratificada
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42
    )
    
    print(f"\nüìä Dataset dividido:")
    print(f"   ‚Ä¢ Train: {len(X_train)} registros")
    print(f"   ‚Ä¢ Test: {len(X_test)} registros")
    
    # Modelo optimizado
    print("\nüå≥ Entrenando Random Forest (optimizado)...")
    rf_model = RandomForestRegressor(
        n_estimators=200,           # M√°s √°rboles
        max_depth=20,               # Mayor profundidad
        min_samples_split=3,        # M√°s flexible
        min_samples_leaf=2,
        max_features='sqrt',        # Considera ra√≠z cuadrada de features
        random_state=42,
        n_jobs=-1,                  # Usa todos los cores
        verbose=0
    )
    
    rf_model.fit(X_train, y_train)
    
    # Predicciones
    y_pred_train = rf_model.predict(X_train)
    y_pred_test = rf_model.predict(X_test)
    
    # M√©tricas
    r2_train = r2_score(y_train, y_pred_train) * 100
    r2_test = r2_score(y_test, y_pred_test) * 100
    rmse_train = np.sqrt(mean_squared_error(y_train, y_pred_train))
    rmse_test = np.sqrt(mean_squared_error(y_test, y_pred_test))
    mae_test = mean_absolute_error(y_test, y_pred_test)
    
    print(f"\nüìä RESULTADOS RANDOM FOREST:")
    print(f"   {'='*50}")
    print(f"   üìà R¬≤ Score (Train): {r2_train:.2f}%")
    print(f"   üìà R¬≤ Score (Test):  {r2_test:.2f}%")
    print(f"   üìâ RMSE (Test):      {rmse_test:,.2f}")
    print(f"   üìâ MAE (Test):       {mae_test:,.2f}")
    print(f"   {'='*50}")
    
    # Validaci√≥n cruzada
    cv_scores = cross_val_score(rf_model, X, y, cv=5, scoring='r2')
    print(f"   üîÑ Cross-Validation (5-fold):")
    print(f"      R¬≤ promedio: {cv_scores.mean()*100:.2f}% (+/- {cv_scores.std()*100:.2f}%)")
    
    # Verificar requisito del 85%
    if r2_test >= 85:
        print(f"\n   ‚úÖ CUMPLE REQUISITO: {r2_test:.2f}% >= 85%")
    else:
        print(f"\n   ‚ö†Ô∏è  NO CUMPLE: {r2_test:.2f}% < 85%")
    
    # Importancia de caracter√≠sticas
    importancias = pd.DataFrame({
        'Feature': features,
        'Importance': rf_model.feature_importances_
    }).sort_values('Importance', ascending=False)
    
    print(f"\nüîç TOP 10 Variables M√°s Importantes:")
    print(importancias.head(10).to_string(index=False))
    
    # Visualizaci√≥n de importancia
    plt.figure(figsize=(10, 6))
    top10 = importancias.head(10)
    plt.barh(top10['Feature'], top10['Importance'], color='skyblue')
    plt.xlabel('Importancia')
    plt.title('Top 10 Variables - Random Forest')
    plt.tight_layout()
    plt.savefig('rf_importancia.png', dpi=300, bbox_inches='tight')
    print("\nüíæ Gr√°fico guardado: rf_importancia.png")
    
    # Visualizaci√≥n de predicciones
    plt.figure(figsize=(10, 6))
    plt.scatter(y_test, y_pred_test, alpha=0.5, s=20)
    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 
             'r--', lw=2, label='Predicci√≥n Perfecta')
    plt.xlabel('Pasajeros Reales')
    plt.ylabel('Pasajeros Predichos')
    plt.title(f'Random Forest - Predicci√≥n vs Real (R¬≤={r2_test:.2f}%)')
    plt.legend()
    plt.tight_layout()
    plt.savefig('rf_predicciones.png', dpi=300, bbox_inches='tight')
    print("üíæ Gr√°fico guardado: rf_predicciones.png")
    
    # Guardar modelo
    modelo_data = {
        'modelo': rf_model,
        'le_ciudad': le_ciudad,
        'le_sistema': le_sistema,
        'le_temporada': le_temporada,
        'features': features,
        'score': r2_test,
        'metricas': {
            'r2_train': r2_train,
            'r2_test': r2_test,
            'rmse': rmse_test,
            'mae': mae_test
        }
    }
    
    joblib.dump(modelo_data, 'modelo_random_forest.pkl')
    print("üíæ Modelo guardado: modelo_random_forest.pkl")
    
    return modelo_data

# ============================================
# ALGORITMO 2: XGBOOST CLASSIFIER (OPTIMIZADO)
# ============================================
def entrenar_xgboost(df):
    """
    XGBoost (Gradient Boosting mejorado) para clasificar demanda
    """
    print("\n" + "="*70)
    print("‚ö° ALGORITMO 2: XGBOOST CLASSIFIER")
    print("="*70)
    
    # Preparar datos
    df_xgb = df.copy()
    df_xgb = df_xgb.dropna(subset=['Pasajeros/dia'])
    
    # Crear categor√≠as de demanda (m√°s equilibradas)
    percentil_33 = df_xgb['Pasajeros/dia'].quantile(0.33)
    percentil_66 = df_xgb['Pasajeros/dia'].quantile(0.66)
    
    print(f"\nüìä Umbrales de Demanda:")
    print(f"   üîµ Baja:  < {percentil_33:,.0f} pasajeros")
    print(f"   üü† Media: {percentil_33:,.0f} - {percentil_66:,.0f} pasajeros")
    print(f"   üî¥ Alta:  > {percentil_66:,.0f} pasajeros")
    
    def categorizar_demanda(pasajeros):
        if pasajeros < percentil_33:
            return 0  # Baja
        elif pasajeros < percentil_66:
            return 1  # Media
        else:
            return 2  # Alta
    
    df_xgb['Demanda_Categoria'] = df_xgb['Pasajeros/dia'].apply(categorizar_demanda)
    
    # Verificar distribuci√≥n
    distribucion = df_xgb['Demanda_Categoria'].value_counts().sort_index()
    print(f"\nüìä Distribuci√≥n de Clases:")
    for cat, nombre in enumerate(['Baja', 'Media', 'Alta']):
        print(f"   {nombre}: {distribucion[cat]} registros ({distribucion[cat]/len(df_xgb)*100:.1f}%)")
    
    # Encoders
    le_ciudad = LabelEncoder()
    le_sistema = LabelEncoder()
    le_temporada = LabelEncoder()
    
    df_xgb['Ciudad_encoded'] = le_ciudad.fit_transform(df_xgb['Ciudad'])
    df_xgb['Sistema_encoded'] = le_sistema.fit_transform(df_xgb['Sistema'])
    df_xgb['Temporada_encoded'] = le_temporada.fit_transform(df_xgb['Temporada'])
    
    # Features
    features = [
        'Ciudad_encoded', 'Sistema_encoded', 'DiaSemana',
        'Pasajeros dia tipico laboral', 'Pasajeros dia sabado',
        'Pasajeros dia festivo', 'Mes', 'A√±o', 'DiaMes', 'Trimestre',
        'EsFinDeSemana', 'EsLaboralPico', 'Temporada_encoded',
        'VariacionLaboral', 'VariacionSabado'
    ]
    
    X = df_xgb[features]
    y = df_xgb['Demanda_Categoria']
    
    # Divisi√≥n estratificada (mantiene proporciones de clases)
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )
    
    print(f"\nüìä Dataset dividido:")
    print(f"   ‚Ä¢ Train: {len(X_train)} registros")
    print(f"   ‚Ä¢ Test: {len(X_test)} registros")
    
    # Modelo XGBoost optimizado
    print("\n‚ö° Entrenando XGBoost (optimizado)...")
    xgb_model = XGBClassifier(
        n_estimators=200,           # M√°s iteraciones
        max_depth=6,                # Profundidad moderada
        learning_rate=0.1,          # Tasa de aprendizaje
        subsample=0.8,              # Submuestra de datos
        colsample_bytree=0.8,       # Submuestra de features
        random_state=42,
        eval_metric='mlogloss',     # M√©trica para multiclase
        use_label_encoder=False,
        n_jobs=-1
    )
    
    xgb_model.fit(X_train, y_train, verbose=False)
    
    # Predicciones
    y_pred_train = xgb_model.predict(X_train)
    y_pred_test = xgb_model.predict(X_test)
    
    # M√©tricas
    accuracy_train = accuracy_score(y_train, y_pred_train) * 100
    accuracy_test = accuracy_score(y_test, y_pred_test) * 100
    precision = precision_score(y_test, y_pred_test, average='weighted') * 100
    recall = recall_score(y_test, y_pred_test, average='weighted') * 100
    f1 = f1_score(y_test, y_pred_test, average='weighted') * 100
    
    print(f"\nüìä RESULTADOS XGBOOST:")
    print(f"   {'='*50}")
    print(f"   üéØ Accuracy (Train):  {accuracy_train:.2f}%")
    print(f"   üéØ Accuracy (Test):   {accuracy_test:.2f}%")
    print(f"   üìà Precision:         {precision:.2f}%")
    print(f"   üìà Recall:            {recall:.2f}%")
    print(f"   üìà F1-Score:          {f1:.2f}%")
    print(f"   {'='*50}")
    
    # Verificar requisito del 85%
    if accuracy_test >= 85:
        print(f"\n   ‚úÖ CUMPLE REQUISITO: {accuracy_test:.2f}% >= 85%")
    else:
        print(f"\n   ‚ö†Ô∏è  NO CUMPLE: {accuracy_test:.2f}% < 85%")
    
    # Reporte detallado
    print(f"\nüìã Reporte de Clasificaci√≥n Detallado:")
    target_names = ['üîµ Baja', 'üü† Media', 'üî¥ Alta']
    print(classification_report(y_test, y_pred_test, target_names=target_names))
    
    # Matriz de confusi√≥n
    cm = confusion_matrix(y_test, y_pred_test)
    print(f"\nüî¢ Matriz de Confusi√≥n:")
    print(cm)
    
    # Visualizaci√≥n de matriz de confusi√≥n
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=['Baja', 'Media', 'Alta'],
                yticklabels=['Baja', 'Media', 'Alta'])
    plt.ylabel('Real')
    plt.xlabel('Predicci√≥n')
    plt.title(f'Matriz de Confusi√≥n - XGBoost (Accuracy={accuracy_test:.2f}%)')
    plt.tight_layout()
    plt.savefig('xgb_confusion_matrix.png', dpi=300, bbox_inches='tight')
    print("\nüíæ Gr√°fico guardado: xgb_confusion_matrix.png")
    
    # Importancia de caracter√≠sticas
    importancias = pd.DataFrame({
        'Feature': features,
        'Importance': xgb_model.feature_importances_
    }).sort_values('Importance', ascending=False)
    
    print(f"\nüîç TOP 10 Variables M√°s Importantes:")
    print(importancias.head(10).to_string(index=False))
    
    # Visualizaci√≥n de importancia
    plt.figure(figsize=(10, 6))
    top10 = importancias.head(10)
    plt.barh(top10['Feature'], top10['Importance'], color='coral')
    plt.xlabel('Importancia')
    plt.title('Top 10 Variables - XGBoost')
    plt.tight_layout()
    plt.savefig('xgb_importancia.png', dpi=300, bbox_inches='tight')
    print("üíæ Gr√°fico guardado: xgb_importancia.png")
    
    # Guardar modelo
    modelo_data = {
        'modelo': xgb_model,
        'le_ciudad': le_ciudad,
        'le_sistema': le_sistema,
        'le_temporada': le_temporada,
        'features': features,
        'accuracy': accuracy_test,
        'percentil_33': percentil_33,
        'percentil_66': percentil_66,
        'metricas': {
            'accuracy_train': accuracy_train,
            'accuracy_test': accuracy_test,
            'precision': precision,
            'recall': recall,
            'f1': f1
        }
    }
    
    joblib.dump(modelo_data, 'modelo_xgboost.pkl')
    print("üíæ Modelo guardado: modelo_xgboost.pkl")
    
    return modelo_data

# ============================================
# PREDICCI√ìN INTERACTIVA
# ============================================
def prediccion_interactiva():
    """
    Sistema de predicci√≥n por consola
    """
    print("\n" + "="*70)
    print("üéØ SISTEMA DE PREDICCI√ìN INTERACTIVA")
    print("="*70)
    
    # Cargar modelos
    try:
        rf_data = joblib.load('modelo_random_forest.pkl')
        xgb_data = joblib.load('modelo_xgboost.pkl')
        print("‚úÖ Modelos cargados exitosamente\n")
    except:
        print("‚ùå Error: Primero debes entrenar los modelos")
        return
    
    # Mostrar opciones
    print("üìç Ciudades disponibles:")
    ciudades = rf_data['le_ciudad'].classes_
    for i, ciudad in enumerate(ciudades):
        print(f"   {i}: {ciudad}")
    
    print("\nüöå Sistemas disponibles:")
    sistemas = rf_data['le_sistema'].classes_
    for i, sistema in enumerate(sistemas):
        print(f"   {i}: {sistema}")
    
    print("\nüå§Ô∏è  Temporadas:")
    print("   0: Normal")
    print("   1: Reapertura")
    print("   2: Restriccion")
    
    # Inputs del usuario
    try:
        ciudad_idx = int(input("\n‚ñ∂Ô∏è  Seleccione ciudad (n√∫mero): "))
        sistema_idx = int(input("‚ñ∂Ô∏è  Seleccione sistema (n√∫mero): "))
        dia_semana = int(input("‚ñ∂Ô∏è  D√≠a de la semana (1=Lunes, 7=Domingo): "))
        mes = int(input("‚ñ∂Ô∏è  Mes (1-12): "))
        a√±o = int(input("‚ñ∂Ô∏è  A√±o: "))
        pas_laboral = float(input("‚ñ∂Ô∏è  Pasajeros d√≠a t√≠pico laboral: "))
        pas_sabado = float(input("‚ñ∂Ô∏è  Pasajeros d√≠a s√°bado: "))
        pas_festivo = float(input("‚ñ∂Ô∏è  Pasajeros d√≠a festivo: "))
        temporada_idx = int(input("‚ñ∂Ô∏è  Temporada (0=Normal, 1=Reapertura, 2=Restriccion): "))
        
    except ValueError:
        print("‚ùå Error: Ingrese valores v√°lidos")
        return
    
    # Preparar datos
    es_fin_semana = 1 if dia_semana in [6, 7] else 0
    es_laboral_pico = 1 if dia_semana in [1, 2, 3, 4, 5] else 0
    dia_mes = 15  # Asumimos d√≠a 15
    trimestre = (mes - 1) // 3 + 1
    variacion_laboral = 0
    variacion_sabado = 0
    
    input_data = pd.DataFrame({
        'Ciudad_encoded': [ciudad_idx],
        'Sistema_encoded': [sistema_idx],
        'DiaSemana': [dia_semana],
        'Pasajeros dia tipico laboral': [pas_laboral],
        'Pasajeros dia sabado': [pas_sabado],
        'Pasajeros dia festivo': [pas_festivo],
        'Mes': [mes],
        'A√±o': [a√±o],
        'DiaMes': [dia_mes],
        'Trimestre': [trimestre],
        'EsFinDeSemana': [es_fin_semana],
        'EsLaboralPico': [es_laboral_pico],
        'Temporada_encoded': [temporada_idx],
        'VariacionLaboral': [variacion_laboral],
        'VariacionSabado': [variacion_sabado]
    })
    
    # Predicciones
    pred_rf = rf_data['modelo'].predict(input_data)[0]
    pred_xgb = xgb_data['modelo'].predict(input_data)[0]
    
    demanda_labels = ['üîµ BAJA', 'üü† MEDIA', 'üî¥ ALTA']
    
    # Mostrar resultados
    print("\n" + "="*70)
    print("üìà RESULTADOS DE PREDICCI√ìN")
    print("="*70)
    
    print(f"\nüå≥ RANDOM FOREST (Regresi√≥n):")
    print(f"   Pasajeros estimados: {pred_rf:,.0f}")
    print(f"   Confianza: R¬≤={rf_data['score']:.2f}%")
    
    print(f"\n‚ö° XGBOOST (Clasificaci√≥n):")
    print(f"   Nivel de demanda: {demanda_labels[pred_xgb]}")
    print(f"   Umbrales:")
    print(f"      ‚Ä¢ Baja:  < {xgb_data['percentil_33']:,.0f}")
    print(f"      ‚Ä¢ Media: {xgb_data['percentil_33']:,.0f} - {xgb_data['percentil_66']:,.0f}")
    print(f"      ‚Ä¢ Alta:  > {xgb_data['percentil_66']:,.0f}")
    print(f"   Confianza: Accuracy={xgb_data['accuracy']:.2f}%")
    
    print("\n" + "="*70)

# ============================================
# MAIN
# ============================================
if __name__ == "__main__":
    print("\n" + "üöÄ"*35)
    print("   SISTEMA DE MACHINE LEARNING - TRANSPORTE P√öBLICO")
    print("   Proyecto: Miner√≠a de Datos 2025-2")
    print("üöÄ"*35)
    
    # 1. Cargar datos
    df = cargar_y_preparar_datos('transporte_limpio.csv')
    
    # 2. Entrenar modelos
    rf_modelo = entrenar_random_forest(df)
    xgb_modelo = entrenar_xgboost(df)
    
    # 3. Resumen final
    print("\n" + "="*70)
    print("‚úÖ RESUMEN FINAL - VALIDACI√ìN DE REQUISITOS")
    print("="*70)
    
    print(f"\nüå≥ Random Forest Regressor:")
    print(f"   ‚Ä¢ Score: {rf_modelo['score']:.2f}%")
    if rf_modelo['score'] >= 85:
        print(f"   ‚Ä¢ Estado: ‚úÖ CUMPLE (‚â•85%)")
    else:
        print(f"   ‚Ä¢ Estado: ‚ö†Ô∏è  NO CUMPLE (<85%)")
    
    print(f"\n‚ö° XGBoost Classifier:")
    print(f"   ‚Ä¢ Accuracy: {xgb_modelo['accuracy']:.2f}%")
    if xgb_modelo['accuracy'] >= 85:
        print(f"   ‚Ä¢ Estado: ‚úÖ CUMPLE (‚â•85%)")
    else:
        print(f"   ‚Ä¢ Estado: ‚ö†Ô∏è  NO CUMPLE (<85%)")
    
    # 4. Predicci√≥n interactiva
    print("\n" + "="*70)
    continuar = input("\n¬øDesea hacer una predicci√≥n interactiva? (s/n): ")
    if continuar.lower() == 's':
        prediccion_interactiva()
    
    print("\n‚úÖ Proceso completado exitosamente")
    print("üíæ Archivos generados:")
    print("   ‚Ä¢ modelo_random_forest.pkl")
    print("   ‚Ä¢ modelo_xgboost.pkl")
    print("   ‚Ä¢ rf_importancia.png")
    print("   ‚Ä¢ rf_predicciones.png")
    print("   ‚Ä¢ xgb_confusion_matrix.png")
    print("   ‚Ä¢ xgb_importancia.png")
    
    print("\nüöÄ Siguiente paso: Crear aplicaci√≥n Streamlit")